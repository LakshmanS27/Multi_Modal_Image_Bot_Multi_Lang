{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CtOJO-if2xDw"
      },
      "outputs": [],
      "source": [
        "!pip install torch==2.6.0 torchvision==0.21.0 torchaudio==2.6.0 --quiet\n",
        "!pip install diffusers transformers accelerate google-generativeai pillow streamlit pyngrok langdetect --quiet\n",
        "!pip install google-generativeai==0.8.5 google-ai-generativelanguage==0.6.15 --quiet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip freeze > requirements.txt"
      ],
      "metadata": {
        "id": "ajwDGLcatEAz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"requirements.txt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "o6Orz2vZtFUe",
        "outputId": "8be8deb7-605d-4df8-a87f-01d077c0c5ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_7fdb384d-b464-421a-8339-f1f10e37a77b\", \"requirements.txt\", 13195)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "GEMINI_API_KEY = input(\"Enter your Google Gemini API Key: \").strip()\n",
        "HF_TOKEN = input(\"Enter your HuggingFace Token (for Stable Diffusion): \").strip()\n",
        "\n",
        "os.environ[\"GEMINI_API_KEY\"] = GEMINI_API_KEY\n",
        "os.environ[\"HF_TOKEN\"] = HF_TOKEN"
      ],
      "metadata": {
        "id": "rJRnMo2n28-k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "from PIL import Image\n",
        "import google.generativeai as genai\n",
        "from diffusers import StableDiffusionPipeline\n",
        "import torch\n",
        "import os\n",
        "from langdetect import detect\n",
        "\n",
        "# CONFIGURE KEYS\n",
        "GEMINI_API_KEY = os.environ.get(\"GEMINI_API_KEY\")\n",
        "HF_TOKEN = os.environ.get(\"HF_TOKEN\")\n",
        "\n",
        "# INIT MODELS\n",
        "genai.configure(api_key=GEMINI_API_KEY)\n",
        "text_model = genai.GenerativeModel(\"gemini-2.5-pro\")\n",
        "vision_model = genai.GenerativeModel(\"gemini-2.5-pro\")\n",
        "\n",
        "@st.cache_resource\n",
        "def load_sd_pipeline():\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    pipe = StableDiffusionPipeline.from_pretrained(\n",
        "        \"CompVis/stable-diffusion-v1-4\",\n",
        "        revision=\"fp16\",\n",
        "        torch_dtype=torch.float16 if device == \"cuda\" else torch.float32,\n",
        "        use_auth_token=HF_TOKEN\n",
        "    ).to(device)\n",
        "    return pipe, device\n",
        "\n",
        "pipe, device = load_sd_pipeline()\n",
        "\n",
        "def chat_with_gemini_multilang(user_input):\n",
        "    detected_lang = detect(user_input)\n",
        "    lang_map = {\n",
        "        'en': 'English',\n",
        "        'es': 'Spanish',\n",
        "        'fr': 'French',\n",
        "        'ta': 'Tamil',\n",
        "        'de': 'German',\n",
        "    }\n",
        "    lang = lang_map.get(detected_lang, 'English')\n",
        "    # Culturally appropriate greeting (simple example)\n",
        "    greetings = {\n",
        "        'English': \"Hello! How can I help you?\",\n",
        "        'Spanish': \"¬°Hola! ¬øC√≥mo puedo ayudarte?\",\n",
        "        'French': \"Bonjour! Comment puis-je vous aider?\",\n",
        "        'Tamil': \"‡Æµ‡Æ£‡Æï‡Øç‡Æï‡ÆÆ‡Øç! ‡Æ®‡Ææ‡Æ©‡Øç ‡Æé‡Æ™‡Øç‡Æ™‡Æü‡Æø ‡Æâ‡Æ§‡Æµ‡Æ≤‡Ææ‡ÆÆ‡Øç?\",\n",
        "        'German': \"Hallo! Wie kann ich Ihnen helfen?\",\n",
        "    }\n",
        "    greeting = greetings.get(lang, greetings['English'])\n",
        "    prompt = f\"You are a helpful AI that replies in {lang} only. User says: {user_input}. Reply accordingly and culturally appropriately.\"\n",
        "    response = text_model.generate_content(prompt)\n",
        "    return f\"{greeting}\\n\\n{response.text}\"\n",
        "\n",
        "def describe_image(img_path):\n",
        "    img = Image.open(img_path)\n",
        "    response = vision_model.generate_content([img, \"Describe this image\"])\n",
        "    return response.text\n",
        "\n",
        "def generate_image(prompt, guidance_scale=8.5):\n",
        "    with torch.autocast(device):\n",
        "        image = pipe(prompt, guidance_scale=guidance_scale).images[0]\n",
        "    return image\n",
        "\n",
        "# STREAMLIT UI\n",
        "st.set_page_config(page_title=\"Multi-Language Multi-Modal Chatbot\", layout=\"wide\")\n",
        "st.title(\"ü§ñ Multi-Language Multi-Modal Chatbot üåê\")\n",
        "\n",
        "mode = st.sidebar.radio(\n",
        "    \"Select mode\",\n",
        "    [\"Text Chat\", \"Image Understanding\", \"Image Generation\"]\n",
        ")\n",
        "\n",
        "if mode == \"Text Chat\":\n",
        "    st.subheader(\"üí¨ Text Chat (Multi-language) with Gemini\")\n",
        "    user_input = st.text_input(\"You:\", key=\"text_input\")\n",
        "    if st.button(\"Send\"):\n",
        "        if user_input:\n",
        "            response = chat_with_gemini_multilang(user_input)\n",
        "            st.markdown(f\"**Bot:** {response}\")\n",
        "\n",
        "elif mode == \"Image Understanding\":\n",
        "    st.subheader(\"üñºÔ∏è Image Understanding with Gemini Vision\")\n",
        "    uploaded_file = st.file_uploader(\"Upload an image\", type=[\"png\", \"jpg\", \"jpeg\"])\n",
        "    if uploaded_file is not None:\n",
        "        img = Image.open(uploaded_file)\n",
        "        st.image(img, caption=\"Uploaded Image\", use_container_width=True)\n",
        "        if st.button(\"Analyze Image\"):\n",
        "            img.save(\"temp_image.png\")\n",
        "            response = describe_image(\"temp_image.png\")\n",
        "            st.markdown(f\"**Bot:** {response}\")\n",
        "            os.remove(\"temp_image.png\")\n",
        "\n",
        "elif mode == \"Image Generation\":\n",
        "    st.subheader(\"üé® Generate Image with Stable Diffusion\")\n",
        "    prompt = st.text_input(\"Enter image prompt:\")\n",
        "    if st.button(\"Generate Image\"):\n",
        "        if prompt:\n",
        "            image = generate_image(prompt)\n",
        "            st.image(image, caption=\"Generated Image\", use_container_width=True)\n",
        "\n",
        "st.markdown(\"---\")\n",
        "st.caption(\"Built with Gemini + Stable Diffusion + Streamlit\")\n"
      ],
      "metadata": {
        "id": "wf6rJ_gG2_Fm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pkill -f streamlit || echo \"No Streamlit process to kill\"\n",
        "from pyngrok import ngrok\n",
        "ngrok.kill()\n",
        "\n",
        "NGROK_TOKEN = input(\"Enter your ngrok authtoken: \").strip()\n",
        "os.environ[\"NGROK_AUTHTOKEN\"] = NGROK_TOKEN\n",
        "\n",
        "!ngrok config add-authtoken $NGROK_AUTHTOKEN"
      ],
      "metadata": {
        "id": "vu5W3jge3D64"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "import threading\n",
        "import os\n",
        "import time\n",
        "\n",
        "def run_streamlit():\n",
        "    os.system(\"streamlit run app.py > /content/logs.txt 2>&1\")\n",
        "\n",
        "thread = threading.Thread(target=run_streamlit)\n",
        "thread.start()\n",
        "\n",
        "time.sleep(10)\n",
        "\n",
        "public_url = ngrok.connect(addr=\"8501\", proto=\"http\")\n",
        "print(f\"üåê Streamlit app running at: {public_url}\")"
      ],
      "metadata": {
        "id": "WzfFWB8T3RSg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}